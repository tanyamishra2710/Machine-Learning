{"metadata":{"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import math\nimport csv\ndef load_csv(filename):\n    lines=csv.reader(open(filename,\"r\"));\n    dataset = list(lines)\n    headers = dataset.pop(0)\n    return dataset,headers\n\nclass Node:\n    def __init__(self,attribute):\n        self.attribute=attribute\n        self.children=[]\n        self.answer=\"\"\n        \ndef subtables(data,col,delete):\n    dic={}\n    coldata=[row[col] for row in data]\n    attr=list(set(coldata))\n    \n    counts=[0]*len(attr)\n    r=len(data)\n    c=len(data[0])\n    for x in range(len(attr)):\n        for y in range(r):\n            if data[y][col]==attr[x]:\n                counts[x]+=1\n        \n    for x in range(len(attr)):\n        dic[attr[x]]=[[0 for i in range(c)] for j in range(counts[x])]\n        pos=0\n        for y in range(r):\n            if data[y][col]==attr[x]:\n                if delete:\n                    del data[y][col]\n                dic[attr[x]][pos]=data[y]\n                pos+=1\n    return attr,dic\n    \ndef entropy(S):\n    attr=list(set(S))\n    if len(attr)==1:\n        return 0\n    \n    counts=[0,0]\n    for i in range(2):\n        counts[i]=sum([1 for x in S if attr[i]==x])/(len(S)*1.0)\n    \n    sums=0\n    for cnt in counts:\n        sums+=-1*cnt*math.log(cnt,2)\n    return sums\n\ndef compute_gain(data,col):\n    attr,dic = subtables(data,col,delete=False)\n    \n    total_size=len(data)\n    entropies=[0]*len(attr)\n    ratio=[0]*len(attr)\n    \n    total_entropy=entropy([row[-1] for row in data])\n    for x in range(len(attr)):\n        ratio[x]=len(dic[attr[x]])/(total_size*1.0)\n        entropies[x]=entropy([row[-1] for row in dic[attr[x]]])\n        total_entropy-=ratio[x]*entropies[x]\n    return total_entropy\n\ndef build_tree(data,features):\n    lastcol=[row[-1] for row in data]\n    if(len(set(lastcol)))==1:\n        node=Node(\"\")\n        node.answer=lastcol[0]\n        return node\n    \n    n=len(data[0])-1\n    gains=[0]*n\n    for col in range(n):\n        gains[col]=compute_gain(data,col)\n    split=gains.index(max(gains))\n    node=Node(features[split])\n    fea = features[:split]+features[split+1:]\n\n    \n    attr,dic=subtables(data,split,delete=True)\n    \n    for x in range(len(attr)):\n        child=build_tree(dic[attr[x]],fea)\n        node.children.append((attr[x],child))\n    return node\n\ndef print_tree(node,level):\n    if node.answer!=\"\":\n        print(\"  \"*level,node.answer)\n        return\n    \n    print(\"  \"*level,node.attribute)\n    for value,n in node.children:\n        print(\"  \"*(level+1),value)\n        print_tree(n,level+2)\n\n        \ndef classify(node,x_test,features):\n    if node.answer!=\"\":\n        print(node.answer)\n        return\n    pos=features.index(node.attribute)\n    for value, n in node.children:\n        if x_test[pos]==value:\n            classify(n,x_test,features)\n            \ndataset,features=load_csv(\"pima-indians-diabetes.csv\")\nnode1=build_tree(dataset,features)\n\nprint(\"The decision tree for the dataset using ID3 algorithm is\")\nprint_tree(node1,0)\ntestdata,features=load_csv(\"id3_test.csv\")\n\nfor xtest in testdata:\n    print(\"The test instance:\",xtest)\n    print(\"The label for test instance:\",end=\"   \")\n    classify(node1,xtest,features)","metadata":{"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"The decision tree for the dataset using ID3 algorithm is\n 0.627\n   0.593\n     1\n   0.155\n     0\n   0.695\n     0\n   1.224\n     1\n   0.222\n     1\n   0.142\n     0\n   0.265\n     0\n   0.403\n     1\n   0.286\n     148\n       106\n         0\n       136\n         1\n   0.326\n     6\n       2\n         0\n       10\n         1\n   0.147\n     0\n   0.970\n     1\n   0.439\n     6\n       5\n         0\n       7\n         1\n   0.742\n     1\n   0.645\n     1\n   1.698\n     0\n   0.161\n     6\n       4\n         1\n       7\n         0\n   0.730\n     0\n   0.283\n     0\n   1.400\n     0\n   0.441\n     1\n   0.408\n     1\n   0.268\n     148\n       163\n         1\n       169\n         1\n       73\n         0\n       128\n         0\n       130\n         0\n   0.254\n     148\n       122\n         0\n       124\n         1\n       187\n         1\n       161\n         0\n       143\n         1\n       107\n         1\n   0.828\n     0\n   0.665\n     1\n   0.173\n     0\n   0.238\n     6\n       0\n         0\n       3\n         0\n       4\n         1\n       6\n         1\n   0.649\n     0\n   0.089\n     0\n   0.435\n     1\n   0.233\n     6\n       0\n         0\n       1\n         1\n   0.317\n     0\n   0.135\n     1\n   0.207\n     0\n   0.279\n     0\n   0.501\n     0\n   0.482\n     0\n   0.381\n     0\n   0.509\n     0\n   0.123\n     0\n   0.547\n     0\n   0.612\n     0\n   0.416\n     0\n   1.441\n     0\n   0.206\n     0\n   0.232\n     1\n   0.203\n     6\n       0\n         1\n       5\n         0\n   0.284\n     0\n   0.427\n     0\n   0.302\n     1\n   0.727\n     148\n       0\n         1\n       107\n         0\n   0.289\n     0\n   0.272\n     1\n   0.682\n     1\n   0.344\n     1\n   0.136\n     0\n   0.597\n     0\n   0.084\n     0\n   0.371\n     1\n   0.705\n     0\n   0.559\n     0\n   0.947\n     0\n   0.833\n     0\n   0.234\n     148\n       133\n         1\n       91\n         0\n   0.546\n     0\n   0.561\n     0\n   0.230\n     6\n       9\n         1\n       4\n         0\n   0.181\n     0\n   0.239\n     1\n   0.463\n     0\n   0.839\n     6\n       0\n         1\n       6\n         0\n   0.451\n     1\n   0.630\n     1\n   0.417\n     0\n   0.426\n     0\n   0.368\n     6\n       2\n         0\n       6\n         1\n   0.733\n     0\n   0.485\n     0\n   0.149\n     0\n   0.717\n     0\n   0.966\n     0\n   0.192\n     0\n   0.673\n     0\n   0.655\n     0\n   0.129\n     1\n   0.875\n     1\n   1.114\n     1\n   1.394\n     1\n   0.343\n     6\n       2\n         0\n       5\n         1\n   0.527\n     0\n   0.626\n     0\n   0.346\n     1\n   0.375\n     0\n   0.118\n     0\n   1.095\n     0\n   0.389\n     0\n   2.137\n     1\n   0.092\n     0\n   0.290\n     0\n   0.421\n     0\n   0.832\n     0\n   0.189\n     0\n   0.391\n     0\n   0.306\n     0\n   0.826\n     1\n   1.159\n     0\n   0.259\n     6\n       2\n         1\n       8\n         1\n       0\n         0\n       12\n         0\n   0.355\n     1\n   0.855\n     1\n   0.300\n     0\n   0.227\n     1\n   0.177\n     0\n   0.261\n     6\n       1\n         0\n       10\n         1\n       5\n         1\n       7\n         0\n   0.338\n     0\n   0.380\n     6\n       9\n         0\n       4\n         1\n   0.292\n     0\n   0.299\n     0\n   1.182\n     1\n   0.678\n     6\n       1\n         0\n       3\n         1\n   1.191\n     1\n   0.249\n     0\n   0.402\n     1\n   0.709\n     0\n   2.329\n     0\n   0.219\n     6\n       1\n         0\n       3\n         1\n   1.781\n     0\n   0.722\n     1\n   0.244\n     0\n   1.318\n     1\n   0.329\n     0\n   0.453\n     0\n   0.243\n     0\n   0.741\n     1\n   1.213\n     1\n   0.260\n     6\n       1\n         0\n       9\n         1\n       6\n         0\n       11\n         1\n   0.398\n     1\n   0.356\n     6\n       3\n         1\n       6\n         0\n   0.840\n     0\n   1.600\n     0\n   0.415\n     0\n   0.170\n     0\n   0.400\n     0\n   0.526\n     0\n   0.209\n     6\n       5\n         1\n       7\n         0\n   0.496\n     148\n       102\n         0\n       88\n         1\n       116\n         0\n   1.144\n     1\n   0.905\n     1\n   0.725\n     0\n   0.572\n     0\n   0.719\n     1\n   1.258\n     1\n   0.745\n     1\n   0.744\n     0\n   0.221\n     0\n   1.282\n     1\n   0.393\n     0\n   0.143\n     0\n   0.263\n     6\n       0\n         0\n       9\n         1\n       10\n         0\n       5\n         0\n   0.085\n     0\n   0.610\n     0\n   1.731\n     0\n   0.542\n     1\n   0.246\n     0\n   0.318\n     0\n   0.358\n     1\n   0.212\n     1\n   0.917\n     0\n   0.631\n     0\n   0.247\n     6\n       0\n         1\n       6\n         0\n   0.285\n     0\n   0.187\n     0\n   0.115\n     0\n   0.331\n     1\n   0.102\n     0\n   0.385\n     0\n   0.194\n     0\n   0.637\n     6\n       2\n         0\n       9\n         1\n   1.321\n     1\n   0.287\n     0\n   0.734\n     1\n   0.615\n     1\n   0.813\n     0\n   0.817\n     1\n   0.718\n     0\n   0.179\n     0\n   0.196\n     1\n   1.251\n     0\n   0.613\n     1\n   0.460\n     0\n   0.591\n     0\n   0.165\n     6\n       8\n         1\n       1\n         0\n       7\n         1\n   0.619\n     0\n   0.166\n     0\n   0.364\n     6\n       0\n         1\n       5\n         0\n   0.251\n     0\n   0.370\n     0\n   0.578\n     1\n   0.160\n     0\n   0.404\n     0\n   0.325\n     1\n   0.549\n     1\n   0.732\n     1\n   0.277\n     1\n   0.773\n     0\n   0.503\n     1\n   0.702\n     1\n   0.845\n     0\n   0.804\n     0\n   1.174\n     0\n   1.057\n     1\n   0.201\n     0\n   0.447\n     1\n   0.454\n     0\n   0.399\n     0\n   2.420\n     1\n   0.151\n     6\n       6\n         0\n       3\n         0\n       5\n         1\n   0.575\n     1\n   0.347\n     0\n   0.605\n     6\n       8\n         1\n       0\n         0\n   0.743\n     1\n   0.925\n     1\n   0.396\n     0\n   0.493\n     0\n   0.672\n     1\n   0.488\n     0\n   0.248\n     6\n       1\n         0\n       3\n         1\n   0.332\n     0\n   0.949\n     0\n   0.892\n     0\n   1.162\n     0\n   0.529\n     1\n   0.652\n     1\n   0.378\n     6\n       5\n         1\n       12\n         0\n   0.487\n     0\n   0.491\n     0\n   0.237\n     0\n   0.241\n     1\n   0.252\n     0\n   0.148\n     6\n       2\n         0\n       9\n         1\n       4\n         0\n   0.128\n     6\n       2\n         0\n       7\n         1\n   0.711\n     1\n   0.362\n     0\n   0.878\n     0\n   0.467\n     1\n   0.787\n     6\n       0\n         0\n       7\n         1\n   0.498\n     0\n   0.323\n     6\n       1\n         0\n       3\n         1\n   0.349\n     6\n       8\n         0\n       1\n         1\n   0.294\n     0\n   0.204\n     0\n   0.514\n     6\n       1\n         0\n       5\n         1\n   0.738\n     0\n   0.771\n     1\n   0.856\n     0\n   0.512\n     0\n   1.390\n     1\n   0.307\n     0\n   0.692\n     148\n       122\n         1\n       151\n         0\n       150\n         1\n       130\n         0\n   0.296\n     1\n   0.433\n     6\n       2\n         1\n       0\n         0\n   0.182\n     0\n   1.222\n     1\n   0.537\n     1\n   0.880\n     0\n   0.412\n     6\n       14\n         1\n       1\n         0\n   0.452\n     6\n       0\n         0\n       3\n         0\n       5\n         1\n   0.303\n     0\n   0.484\n     1\n   0.432\n     0\n   0.805\n     1\n   0.515\n     0\n   0.881\n     0\n   0.554\n     1\n   0.394\n     0\n   0.175\n     0\n   1.292\n     1\n   0.624\n     0\n   0.571\n     0\n   0.874\n     0\n   0.867\n     1\n   0.121\n     6\n       3\n         0\n       6\n         1\n   0.557\n     6\n       3\n         0\n       11\n         1\n   0.130\n     0\n   0.220\n     1\n   0.138\n     0\n   0.704\n     0\n   0.190\n     0\n   0.871\n     1\n   0.315\n     0\n   0.808\n     1\n   0.534\n     1\n   0.483\n     0\n   0.150\n     6\n       3\n         0\n       4\n         1\n   0.674\n     6\n       2\n         1\n       6\n         0\n   0.654\n     0\n   0.472\n     0\n   1.021\n     0\n   0.330\n     0\n   0.696\n     0\n   0.660\n     6\n       0\n         0\n       5\n         1\n   0.319\n     1\n   0.507\n     0\n   0.532\n     0\n   0.686\n     148\n       179\n         1\n       107\n         0\n   0.580\n     0\n   0.374\n     0\n   0.582\n     0\n   0.126\n     0\n   0.297\n     1\n   0.225\n     0\n   0.200\n     0\n   0.210\n     0\n   0.588\n     1\n   0.748\n     0\n   0.564\n     0\n   0.258\n     6\n       1\n         0\n       3\n         1\n       10\n         0\n       5\n         0\n       0\n         1\n       7\n         1\n   1.353\n     1\n   1.001\n     1\n   0.420\n     0\n   0.335\n     1\n   0.199\n     1\n   0.479\n     1\n   0.930\n     0\n   0.629\n     0\n   0.539\n     1\n   0.962\n     6\n       0\n         0\n       1\n         1\n   0.446\n     0\n   0.345\n     1\n   0.528\n     6\n       1\n         0\n       12\n         1\n   0.785\n     1\n   0.997\n     0\n   0.497\n     0\n   0.107\n     0\n   0.264\n     1\n   0.376\n     1\n   0.687\n     6\n       8\n         1\n       1\n         0\n       7\n         0\n   0.253\n     0\n   0.699\n     0\n   1.461\n     0\n   0.658\n     0\n   0.174\n     0\n   2.288\n     1\n   0.158\n     148\n       197\n         1\n       108\n         0\n   0.271\n     0\n   0.932\n     0\n   0.278\n     1\n   0.816\n     0\n   0.236\n     0\n   0.164\n     0\n   0.295\n     0\n   0.956\n     1\n   0.217\n     0\n   0.229\n     0\n   0.141\n     6\n       0\n         1\n       2\n         0\n       10\n         1\n   0.245\n     6\n       13\n         0\n       5\n         0\n       10\n         0\n       6\n         1\n   0.226\n     1\n   0.270\n     148\n       131\n         1\n       152\n         0\n       78\n         0\n       133\n         1\n   1.022\n     0\n   0.583\n     6\n       13\n         1\n       1\n         0\n       5\n         1\n   0.352\n     0\n   0.231\n     0\n   0.366\n     0\n   0.235\n     6\n       2\n         0\n       4\n         1\n       7\n         0\n   0.218\n     0\n   0.411\n     0\n   0.434\n     0\n   0.282\n     6\n       1\n         1\n       9\n         0\n   0.560\n     0\n   0.893\n     1\n   0.647\n     0\n   0.455\n     6\n       0\n         1\n       2\n         0\n   0.337\n     6\n       2\n         1\n       5\n         0\n       7\n         1\n   0.145\n     0\n   0.666\n     0\n   0.735\n     0\n   0.646\n     1\n   0.167\n     0\n   0.153\n     6\n       5\n         0\n       15\n         1\n   0.955\n     1\n   0.134\n     0\n   0.342\n     0\n   0.680\n     0\n   0.466\n     0\n   0.801\n     0\n   0.525\n     0\n   0.661\n     1\n   0.314\n     6\n       0\n         1\n       3\n         0\n   0.176\n     0\n   0.499\n     0\n   0.968\n     6\n       2\n         0\n       3\n         1\n   0.262\n     0\n   0.759\n     1\n   0.304\n     0\n   0.340\n     6\n       2\n         0\n       4\n         0\n       5\n         1\n   0.144\n     0\n   0.328\n     1\n   0.351\n     0\n   1.391\n     1\n   1.476\n     0\n   0.731\n     1\n   0.430\n     0\n   0.831\n     1\n   0.255\n     0\n   0.365\n     6\n       0\n         1\n       1\n         0\n   0.178\n     6\n       13\n         0\n       6\n         1\n   0.269\n     0\n   0.100\n     0\n   0.757\n     1\n   0.444\n     0\n   0.601\n     0\n   0.677\n     0\n   1.076\n     0\n   0.595\n     0\n   0.803\n     1\n   0.127\n     1\n   0.693\n     1\n   0.536\n     6\n       1\n         0\n       4\n         1\n   0.565\n     1\n   0.096\n     0\n   0.851\n     1\n   0.545\n     0\n   0.101\n     0\n   0.703\n     0\n   0.240\n     1\n   1.893\n     1\n   0.587\n     148\n       44\n         0\n       166\n         1\n       91\n         0\n   0.569\n     1\n   0.157\n     0\n   0.904\n     0\n   1.268\n     0\n   1.101\n     0\n   1.034\n     1\n   0.191\n     0\n   0.510\n     1\n   0.215\n     0\n   0.543\n     1\n   0.465\n     1\n   0.431\n     1\n   0.407\n     0\n   0.186\n     0\n   0.223\n     0\n   0.256\n     0\n   0.388\n     0\n   0.516\n     1\n   0.767\n     0\n   0.422\n     6\n       2\n         1\n       1\n         0\n   0.361\n     1\n   0.280\n     0\n   0.180\n     6\n       13\n         0\n       6\n         1\n   0.313\n     0\n   0.457\n     0\n   0.336\n     0\n   0.305\n     0\n   0.551\n     6\n       0\n         1\n       1\n         0\n       3\n         0\n       8\n         0\n   0.183\n     6\n       8\n         1\n       1\n         0\n   0.495\n     0\n   0.122\n     0\n   0.159\n     0\n   0.423\n     1\n   0.821\n     0\n   0.464\n     0\n   0.108\n     0\n   0.607\n     0\n   1.072\n     1\n   0.721\n     1\n   0.257\n     6\n       2\n         0\n       13\n         1\n       7\n         1\n   0.520\n     6\n       0\n         0\n       2\n         0\n       4\n         1\n   0.163\n     1\n   0.341\n     0\n   1.138\n     0\n   0.267\n     0\n   0.334\n     6\n       0\n         1\n       1\n         0\n   0.205\n     6\n       0\n         1\n       1\n         0\n       10\n         1\n   0.640\n     6\n       8\n         1\n       5\n         0\n   1.136\n     1\n   0.600\n     0\n   0.825\n     1\n   0.614\n     0\n   1.189\n     1\n   0.443\n     6\n       8\n         1\n       4\n         0\n   0.188\n     0\n   0.140\n     0\n   0.395\n     1\n   0.137\n     6\n       8\n         1\n       12\n         0\n   0.409\n     0\n   0.766\n     0\n   0.502\n     1\n   0.133\n     0\n   1.699\n     0\n   0.171\n     0\n   0.382\n     0\n   0.471\n     0\n   0.162\n     0\n   0.156\n     0\n   0.926\n     1\n   0.198\n     0\n   0.293\n     6\n       1\n         1\n       3\n         0\n   0.586\n     6\n       2\n         0\n       7\n         1\n   0.088\n     6\n       2\n         0\n       1\n         1\n   0.154\n     0\n   0.933\n     1\n   0.698\n     0\n   0.324\n     0\n   0.598\n     0\n   0.401\n     0\n   0.383\n     1\n   0.944\n     0\n   0.761\n     6\n       2\n         0\n       3\n         1\n   0.886\n     0\n   1.096\n     0\n   0.197\n     6\n       0\n         0\n       1\n         0\n       3\n         1\n   1.127\n     1\n   0.078\n     0\n   0.419\n     0\n   1.154\n     1\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-1feadb619842>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The decision tree for the dataset using ID3 algorithm is\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0mprint_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m \u001b[0mtestdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"id3_test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-1feadb619842>\u001b[0m in \u001b[0;36mload_csv\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'id3_test.csv'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'id3_test.csv'","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}